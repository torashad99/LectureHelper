you
this lecture is about the tax retrieval
problem
this picture shows our overall plan for
lectures in the last lecture we talked
about the high level strategies for text
access we talked about the push versus
poor so trainings are the main tools for
supporting the poor mould starting from
this lecture we're going to talk about
the how search engines work in detail so
first it's about the tax retrieval
problem we're going to talk about the
three things in this lecture first we
will define tax retrieval second we're
going to make a comparison between tax
retrieval and the related tasks database
retrieval finally we're going to talk
about the document selecting versus
document ranking as two strategies for
responding to a user's query so what is
tax retrieval it should be a task that's
familiar to most of us because we are
using web search engines all the time so
tax retrieval is basically a task where
the system would respond to a user's
query with relevant documents basically
to support the query as one way to
implement the poor mode of information
access so the scenario is the following
you have a collection of text documents
these documents could be all the web
pages on the web or all the literature
articles in the digital library or maybe
all the text files in your computer a
user would typically give a query to the
system to express the information need
and then the system would return
relevant documents to users relevant
documents refer to those documents that
are useful to the user who typing the
now this task is often called
information retrieval but literally
information retrieval would broadly
include the retrieval of other non
textual information as well for example
audio video etc it's worth noting that
tax retrieval is at the core of
information table in the sense that
other media's such as video can be
retrieved by exploiting the companion
text data so for example current the
image search engines actually match a
user's query with the companion text
data of the image this problem is also
called as the search problem and the
technology is often called a search
technology industry if you have taken a
course in databases and we use for the
pause the lecture at this point and
think about the differences between tax
retrieval and database retrieval now
these two tasks are similar in many ways
but there are some important differences
so spend a moment to think about the
differences between the two think about
the data and information managed by a
search engine versus those that are many
managed by a database system think about
the difference between the queries that
you typically specify for a database
system versus the queries that are typed
typing in by users on a search engine
and then finally think about the insults
what's the difference between the two
okay so if we think about the
information or data manager by the two
systems we will see that in tax retrieve
all the data is unstructured it's free
tax but in the databases they are
structured data where there is a clear
define a schema to tell you this column
is
the names of people in that column is
ages etc in instructor text it's not
obvious what are the names of people
mentioned in the text because of this
difference we can also see that text
information tends to be more ambiguous
and we talked about that in the natural
and processing lab chip whereas in
databases the data tend to have where
they find the semantics
there is also important difference in
the queries and this is partly due to
the difference in the information or
data so text queries tend to be
ambiguous
whereas in database search the queries
are typically where defined think about
the sequel query that would clearly
specify what records to be returned so
it has very well defined the semantics
keyword queries or natural language
queries tend to be incompleted also in
that it doesn't really fully specify
what Dawkins should be retrieve whereas
in the database search the sequel query
can be regarded as a complete a
specification for what should be
returned and because of these
differences the answers would be also
different in the case of text retrieval
we are looking for rather than the
documents in the database search we are
retrieving records or match records with
the sequel query more precisely now in
the case of text reachable what should
be the right answers to a query is not
very well specified as we just discussed
so it's unclear what should be the right
answers to a query and this has very
important consequences and that is tax
retrieval is an empirically defined
problem
so this is a problem because if it's
empirically defined then we cannot
mathematically prove one method is
better than another method that also
means we must rely on empirical
evaluation involving users to know which
method works better and that's why we
have unlocked you actually more than one
lectures to cover the issue of
evaluation because this is a very
important topic for search engines
without knowing how to evaluate an
algorithm appropriately there is no way
to tell whether we have got a better
algorithm or whether one system is
better than another so now let's look at
the problem in a formal way
so the society's use of formal
formulation of the tax retrieval problem
first we have our vocabulary set which
is just a set of words in a language now
here we are considering just one
language but in reality on the web there
might be multiple natural languages we
have text there are in all kinds of
languages but here for simplicity we
just assume there is one kind of
language as the techniques used for
retrieving data from multiple languages
are more or less similar to the
techniques used for retrieving documents
in one language although there is
important difference the principles and
methods are very similar next we have
the query which is a sequence of words
and so here you can see the query is
defined as a sequence of words each Q
sub I is a word in the vocabulary a
document is defined in the same way so
it's also a sequence of words and here T
sub IJ
is also a word in the vocabulary now
typically the documents are much longer
than queries but there are also cases
where the documents may be very short so
you can think about what might be an
example of that case I hope you can
think of Twitter search right tweets are
very short but in general documents are
longer than the queries now then we have
a collection of documents and this
collection can be very large so think
about the web it could be very large and
then the goal of tax retrieval is to
find the set of relevant documents which
we denote by R of Q because it depends
on the query and this is in general a
subset of all the documents in the
collection unfortunately this set of
relevant documents is generally unknown
and user dependent in the sense that for
the same query typing by different users
the expected relevant documents may be
different the query given to us by the
user is only a hint on which document
that should be in this set and indeed
the user is generally unable to specify
what exactly should be in this set
especially in the case of web search
where the tracking so large the user
doesn't have complete knowledge about
the whole fraction so the best search
system can do is to compute an
approximation of this relevant document
set so we denoted by our prime of Q so
formally we can see the task is to
compute this R prime of Q approximation
of the relevant documents so how can we
do that
now imagine if you are now asked to
write a program to do this what would
you do now think for a moment right so
these are the your input with the query
the documents and then you are the
computer the answers to this query which
is set of documents that would be useful
to the user so how would you solve the
problem now in general there are two
strategies that we can use right the
first two strategies without documents
in action and that is we're going to
have a binary classification function or
binary classifier that's a function that
would take a document and query as input
and then give a 0 or 1 as output to
indicate whether this document is
relevant to the query or not so in this
case you can see the document the the
redmond locking in the set is defined as
follows it basically all the documents
that have a value of 1 by this function
and so so in this case you can see the
system must have decided if a document
is relevant or not basically there has
to say whether it's 1 or 0 and this is
called absolute the remans basically it
needs to know exactly whether it's going
to be useful to the user or totally
there's another strategy called document
arranging now in this case the system is
not going to make a call where the
document is Renmin or not but rather the
system is going to use a real variable
function f here that would simply give
us a value that would indicate which
document is more likely relevant so it's
not going to make a call whether this
document is relevant or not but rather
you would say which document is more
likely relevant so this function then
can be
used to render the documents and then
we're gonna let it use the decide where
to stop when the user looks at the
documents so we have a threshold theta
here to determine what documents should
be in this approximation set and we can
assume that all the Rockies that are
ranked above this ratio are in this set
because in the fact these are the
documents that we deliver to the user
and theta is cut off terminal by the
user so here we've got some
collaboration from the user in some
sense because we don't really make a
cut-off and the user kind of helped the
system make a cut-off so in this case
the system only needs to decide if one
document is more likely relevant than
another and that is it only needs to
determine relative relevance as opposed
to absolute awareness now you can
probably already sense that relevant
relative relevance would be easier to
determine the absolute relevance because
in the first case we have to say exactly
whether the document is relevant or not
and it turns out that ranking is indeed
generally preferred to talk in the
selection so let's look at this these
two strategies in more detail so this
picture shows how it works
so on the left side we see these
documents and we use the process to
indicate the relevant documents so we
can see the true relevant documents here
consists this set of sure our documents
consist of these pluses
these documents and with the popular
selection function and we're going to
basically classify them into two groups
relevant lock
and non-random the ones of course the
classifier will not be perfect so it
will make mistakes so here we can see in
the approximation of the relevant
documents we have got some non redundant
documents and similarly there is a
relevant document that that's
misclassified has non relevant in the
case of doctrine the ranking we can see
the system simply simply ranks all the
documents in the descending order of the
scores and then we're gonna let the user
stop wherever the user wants to stop so
if a user wants to examine more
documents then the user would go down
the list to examine more and stop at a
lower position but if the user only
wants to read a few relevant documents
the user might stop at the top position
so in this case the user stops at t4 so
in effect we have delivered these four
documents to our user so as I said
ranking is generally preferred and one
of the reasons is because the classifier
in the case of document selection is
unlikely accurate why because the only
crew is usually the query but query may
not be accurate in the sense that it
could be overly constrained for example
you might expect the relevant documents
to talk about all these topics you by
using specific vocabulary and as a
result you might match no relevant
documents because in the collection no
others have discussed with the topic
using these vocabularies so in this case
you will see there is this problem of no
relevant documents to return in the case
of over a constrained query on the other
hand if the query is under constraint
for example if the query does not
have sufficient that this one dating
world to find the relevant documents you
may actually end up by having her over
delivery and this is when you thought
these words might be sufficient to help
you find the relevant documents but it
turns out that they are not sufficient
and there are many distracting documents
using similar words and so this is the
case of all the delivery unfortunately
it's very hard to find the right
position between these two extremes why
because when the user is looking for the
information in general the user does not
have a good knowledge about the name for
missing that we found and in that case
the user does not have a good knowledge
about what vocabularies will be used in
those rare documents so it's very hard
for user to pre specify the right level
of our constraints even if the
classifier is accurate we also still
want to rank these relevant documents
because they are generally not equally
relevant relevance is often a matter of
degree
so we must prioritize these documents
for a user to examine and this note that
this prioritization is very important
because a user cannot digest all the
contents and once the user generally
would have to look at each document
sequentially and therefore it would make
sense to feed the users with the most
relevant documents and that's what
ranking is doing so for these reasons
ranking is general prefer now this
preference also has the theoretical
justification and this is given by the
probability ranking principle in the end
of this lecture there is a reference for
this this principle says returning a
ranked list of documents in
sending order of probability that the
document is relevant to the query is the
optimal strategy under the following two
assumptions first the utility of a
document to a user is independent of the
utility of any other document second a
user would be assumed that who browse
the results sequentially now it's easy
to understand why these two assumptions
are needed in order to justify for the
ranking strategy because if the
documents are independent then we can
evaluate the utility of each document
separately and this would allow us to
compute a score for each document
independently and then we're going to
rank these documents based on those
scores the second assumption is to say
that that the user would indeed a follow
the ranked list if the user is not going
to follow the ranked list is not going
to examine the documents of sequentially
then obviously the ordering would not be
optimal so under these two assumptions
we can theoretically justify the ranking
strategy is in fact the best you could
do now I've put one question here to
these two assumptions hope now I suggest
you to pause the lecture for a moment to
think about these
now can you think of some examples that
would suggest these assumptions aren't
necessarily true
now if you think for a moment you may
realize none of the assumptions is
actually true for example in the case of
independence assumption we might have
identical documents that have similar
content or exactly same content if you
look at each of them alone each is
Redmund but if the user has already seen
one of them we assume it's generally not
very useful for the user to see another
similar or duplicated one
so clearly the utility of the document
is dependent on other documents that the
user has seen in some other cases you
might see a scenario where one document
that may not be useful to the user but
when three particular documents are put
together they provide an answer to the
users question so this is a collective
relevance and that also suggests that
the value of the document might depend
on other documents sequential browsers
in January would make sense if you have
a ranked list there but even if you have
a ranked list there is evidence showing
that users don't always just go strictly
sequentially through the entire list
they sometimes would look at the bottom
for example or skip some and if you
think about the more complicated
interface that we could possible and use
like two dimensional interface where you
can put additional information on the
screen then Secunia browsing is a very
restrictive assumption so the point here
is that none of these assumptions is
really true but lived on us the
probability rendering principle
established some solid foundation for
ranking as a primary task for search
engines and this has actually been the
basis for a lot of research work
information retrieval and many
algorithms have been designed that based
on this assumption
despite that the assumptions are
necessary to and we can address this
problem by doing post-processing of a
ranked list for example to remove
redundancy so to summarize this lecture
the main points that you can take away
are the following first Tex retrieval is
an empirical define the problem and that
means which algorithm is better must be
judged by the users second document
ranking is generally preferred and this
will help users prioritize examination
of search without and this is also the
bypass the difficulty in determining
absolute relevance because we can get
some help from users in determining
where to make the cutoff it's more
flexible so this further suggests that
the main technical channeling in
designing and so changing is redesigned
effective ranking function in other
words we need to define what is the
value of this function f on the query
and documented pair a holo design such a
function is the main topic in the
following lectures there are two suggest
to the additional readings the first is
the classic paper on probability ranking
principle the second is a must read for
anyone doing research information table
it's a classical IR book which has
excellent coverage of the main research
results in early days up to the time
when the book was written chapter 6 of
this book has in-depth discussion of the
problem in the ranking principle and
probabilistic of retrieval models in
general